<div id="technicalDoc" class="block"><span lang="de">
   <p>Burchards Dekret Digital erarbeitet eine Digital- und Druckedition, die den komplexen und mehrschichtigen Entstehungs- und
      Entwicklungsprozess des Dekrets in enger Rückbindung an kodikologische
      Phänomene erschließt. Hierfür greift das Projekt auf eine digitale
      Infrastruktur zurück, die auf den folgenden neun Säulen fußt:</p>
   <div style="text-align: center;">
      <figure class="figure"><img src="../img/pillars.png" class="figure-img img-fluid" alt="Die neun Säulen" title="Die neun Säulen"><figcaption class="figure-caption">Die neun Säulen</figcaption>
      </figure>
   </div>
   <p>Auf Basis dieser Infrastruktur wurde hierfür ein modularer und
      halbautomatisierter Workflow entwickelt, der aus der automatisierten
      Layouterkennung und Transkription in Transkribus, Postprocessing,
      Speicherung in exist-db, frameworkgestützter TEI-Codierung in OxygenXML
      sowie der Kollation in Collatex besteht. Daran schließt sich die
      Transformation der Daten für Druck und Webpräsentation an sowie die <a href="https://github.com/michaelscho/bdd-coordinates" target="_blank">automatisierte Generierung Ground Truth</a> für Finetuning und
      Neutraining von Deep Learning-Modellen für unterschiedliche Zusammenhänge.
      Die generierten TEI-Dateien werden über ein <a href="https://gitlab.rlp.net/adwmainz/projekte/burchards-dekret-digital/data" target="_blank">Datenrepositorium</a> vorgehalten und durch Javascript in die
      Webansicht der Edition geladen. Die Anzeige der Handschriften und erzeugter
      Annotationen erfolgt über IIIF in Mirador Viewer.</p>
   <div style="text-align: center;">
      <figure class="figure"><img src="../img/workflow.png" class="figure-img img-fluid" alt="Workflow" title="Workflow"><figcaption class="figure-caption">Workflow</figcaption>
      </figure>
   </div>
   <p>Im Zentrum des Workflows stehen damit die Kodierung der Textzeugen in
      OxygenXML sowie die automatisierte Texterkennung durch Transkribus, wobei
      sich gegenwärtig die Überführung des ATR-Workflows zu Kraken in Vorbereitung
      befindet. Da die autornahen Textzeugen alle dem Wormser Skriptorium
      entstammen und einer kleinen Gruppe von Schreibern zuzuordnen sind, konnte
      ein effizientes ATR-Modell mit einer Character Error Rate (CER) von etwa 2 %
      durch das Training an ca. 100.000 Wörtern erreicht werden.</p>
   <p>Dabei wurde bewusst ein Modell trainiert, das Abkürzungen und orthographische
      Varianz der Handschriften unter Rückgriff auf <a href="https://mufi.info/" target="_blank">Mufi-Sonderzeichen</a> beibehält.
      Die Auflösung der Abkürzungen erfolgt dann durch <a href="https://github.com/michaelscho/transpy" target="_blank">Pythonskripte</a> anhand festgelegter Regeln und Wortlisten, bzw. in
      Zukunft durch die Implementierung eines <a href="https://zenodo.org/records/16628613" target="_blank">Deep
         Learning-Verfahrens</a>, das anhand der im Projekt erzeugten Daten
      trainiert wird.</p>
   <p>Das Layout der Handschriften wird ebenfalls automatisiert erkannt und
      annotiert. Hierfür wurde zunächst ein <a href="https://github.com/lquirosd/P2PaLA" target="_blank">Pa2PaLa-Modell</a> trainiert, das Kopf- und Fußzeile der Handschrift,
      Spalten, Kapitelnummern und Inskriptionen identifiziert. Gegenwärtig erfolgt
      zudem das Training eines Kraken-Modells anhand des annotierten PageXML von
      sieben Handschriften, das nebst der verwendeten Daten auf <a href="https://github.com/michaelscho/bdd-segmentation-data" target="_blank">Github</a> zur Verfügung steht.</p>
   <p>Das so aufbereitete Material wird per API aus Transkribus als PageXML
      exportiert und im Rahmen einer Python Pipeline postprozessiert. Dies
      beinhaltet die Auflösung der Abkürzungen, Berechnung von IIIF-konformen
      Bildkoordinaten der Text-Zeilen sowie die Überführung in projektkonformes
      TEI. Diese Daten dienen dann als Ausgangspunkt für die editorische
      Erschließung, Korrektur und Anreicherung in OxygenXML. Nach Abschluss der
      editorischen Arbeiten wird das korrigierte Material erneut in einer <a href="https://github.com/michaelscho/bdd-coordinates" target="_blank">Python
         Pipeline</a> prozessiert und automatisiert in Ground Truth Material für
      das Training weiterer Deep Learning-Modelle überführt.</p>
   <p>Die so kodierten Textzeugen können nun in einer projektinternen <a href="https://github.com/michaelscho/Collation" target="_blank">CollateX-Implementierung</a> kollationiert bzw. als <a href="https://gitlab.rlp.net/adwmainz/projekte/burchards-dekret-digital/data" target="_blank">Transkriptionsdateien</a> nebst der generierten Ground Truth
      im Datenrepositorium abgelegt werden.</p>
   <p>Von dort werden die Daten durch Javascript abgefragt und in die Webedition
      gespielt, die über GitLab Pages gehostet wird. Dabei werden die im Zuge der
      Layouterkennung generierten und ins IIIF-Format transformierten Koordinaten
      genutzt, um wichtige Phänomene der Handschriften per IIIF-Schnittstelle im
      Bild darzustellen. Auf die gleiche Weise können <a href="https://www.w3.org/TR/annotation-model/#annotations" target="_blank">Web Annotation</a> generiert werden, um die Anzeige komplexer Phänomene
      in Mirador Viewer zu ermöglichen.</p>
   <div style="text-align: center;">
      <figure class="figure"><img src="../img/mirador.png" class="figure-img img-fluid" alt="Mirador viewer" title="Mirador viewer"><figcaption class="figure-caption">Mirador viewer</figcaption>
      </figure>
   </div></span><span lang="en">
   <p>Burchard's Decree Digital is developing a digital and print edition that explores the complex and multi-layered process of the decree's
      creation and development in close connection with codicological phenomena.
      To this end, the project utilises a digital infrastructure based on the
      following nine pillars:</p>
   <div style="text-align: center;">
      <figure class="figure"><img src="../img/pillars.png" class="figure-img img-fluid" alt="The nine Pillars" title="The nine Pillars"><figcaption class="figure-caption">The nine Pillars</figcaption>
      </figure>
   </div>
   <p>Based on this infrastructure, a modular and semi-automated workflow was
      developed, consisting of automated layout recognition and transcription in
      Transkribus, post-processing, storage in exist-db, framework-supported TEI
      coding in OxygenXML and collation in Collatex. This is followed by the
      transformation of the data for print and web presentation as well as the
      <a href="https://github.com/michaelscho/bdd-coordinates" target="_blank">automated generation of ground truth</a> for fine-tuning and retraining
      of deep learning models for different contexts. The generated TEI files are
      stored in a <a href="https://gitlab.rlp.net/adwmainz/projekte/burchards-dekret-digital/data" target="_blank">data repository</a> and loaded into the web view of the
      edition using Javascript. The manuscripts and generated annotations are
      displayed via IIIF in Mirador Viewer.</p>
   <div style="text-align: center;">
      <figure class="figure"><img src="../img/workflow.png" class="figure-img img-fluid" alt="Workflow" title="Workflow"><figcaption class="figure-caption">Workflow</figcaption>
      </figure>
   </div>
   <p>The encoding of the text witnesses in OxygenXML and the automated text
      recognition by Transkribus are at the centre of the workflow, whereby the
      transfer of the ATR workflow to Kraken is currently in preparation. As the
      text witnesses which are closely related to the author all originate from
      the Worms scriptorium and can be assigned to a small group of scribes, we
      were able to achieve an efficient ATR model with a character error rate
      (CER) of around 2% due to training on approx. 100,000 words.</p>
   <p>A joined model that retains the abbreviations and orthographic variance of
      the handwriting using <a href="https://mufi.info/" target="_blank">Mufi
         special characters</a> was deliberately trained. The abbreviations are
      then resolved by <a href="https://github.com/michaelscho/transpy" target="_blank">Python scripts</a> using defined rules and word lists, or in
      future by implementing a <a href="https://zenodo.org/records/16628613" target="_blank">deep learning
         process</a> that is trained using the data generated in the project.</p>
   <p>The layout of the manuscripts is also recognised and annotated automatically.
      For this purpose, a <a href="https://github.com/lquirosd/P2PaLA" target="_blank">Pa2PaLa model</a> was first trained, which identifies the header and
      footer of the manuscript, columns, chapter numbers and inscriptions.
      Currently, a Kraken model is also being trained using the annotated PageXML
      of seven manuscripts, which is available on <a href="https://github.com/michaelscho/bdd-segmentation-data" target="_blank">Github</a> along with the data used.</p>
   <p>The material prepared in this way is exported from Transkribus as PageXML via
      API and post-processed in a Python pipeline. This includes resolving the
      abbreviations, calculating IIIF-compliant image coordinates of the text
      lines and converting them into project-compliant TEI. This data then serves
      as the starting point for the editorial indexing, correction and enrichment
      in OxygenXML. Once the editorial work has been completed, the corrected
      material is processed again in a <a href="https://github.com/michaelscho/bdd-coordinates" target="_blank">Python
         pipeline</a> and automatically converted into ground truth material for
      training further deep learning models.
      </p>
   <p>The encoded text witnesses are now collated in a project-internal <a href="https://github.com/michaelscho/Collation" target="_blank">CollateX
         implementation</a>; additionally, they are stored as <a href="https://gitlab.rlp.net/adwmainz/projekte/burchards-dekret-digital/data" target="_blank">transcription files</a> together with the generated ground
      truth in the data repository.
      </p>
   <p>Finally, the data is retrieved by Javascript and uploaded to the web edition,
      which is hosted via GitLab Pages. The coordinates that were generated during
      the layout recognition stage are transformed into IIIF format so
      that they can be used to visually display important phenomena of the
      manuscripts via the IIIF interface. In the same way, <a href="https://www.w3.org/TR/annotation-model/#annotations" target="_blank">web annotations</a> can be
      generated to enable the display of complex phenomena in Mirador Viewer. 
      </p>
   <div style="text-align: center;">
      <figure class="figure"><img src="../img/mirador.png" class="figure-img img-fluid" alt="Mirador viewer" title="Mirador viewer"><figcaption class="figure-caption">Mirador viewer</figcaption>
      </figure>
   </div></span></div><div id="teiHandschriftenDBDoc" class="block"><span lang="de">
   <p>zu erledigen</p></span><span lang="en">
   <p>to do</p></span></div><div id="teiEditionDoc" class="block"><span lang="de">
   <p>zu erledigen</p></span><span lang="en">
   <p>to do</p></span></div><div id="webEditionDoc" class="block"><span lang="de">
   <p>Alle Textzeugen des <i>Decretum Burchardi</i> werden in einer
      Handschriften-Datenbank in der Abteilung <a href="../html/mss.html">Handschriften</a> aufgenommen und
      verfügbar gemacht. Über die Schaltfläche <b>Buch zum Arbeitsbereich hinzufügen</b> auf
      jeder Webseite der aufgelisteten Handschriften sind die bereits
      transkribierten Teile zu finden. Alle Begleittexte des Dekrets werden
      aufgelistet und mit Literatur- und Editionshinweisen angereichert, da sie
      gegebenenfalls auch Hinweise auf Abhängigkeiten der Handschriften
      untereinander sichtbar machen. Ziel ist es, über eine reine Auflistung der
      Handschriften hinaus ein multifunktionales Werkzeug für die Erforschung des
      <i>Decretum Burchardi</i> bereitzustellen.</p>
   <p>Der <a href="../html/desktop.html">Arbeitsbereich</a> bietet eine digitale Umgebung, die an Burchards
      Schreibtisch während der Abfassung des Dekrets erinnert. Hier können derzeit
      über die Schaltfläche <b>Ressource hinzufügen</b> (unter <b>Arbeitsmaterial</b>) die Transkriptionen der Bücher
      aus den Handschriften aus Bamberg, Frankfurt, Köln und dem Vatikan
      hinzugefügt werden, die Sie einsehen und vergleichen möchten. Jedes Buch ist
      mit einer Transkription des Textes, einer Ansicht seiner Struktur,
      digitalisierten Bildern der Handschrift und Metadaten
      angereichert. Über die Schaltfläche <b>Transkriptionsansichten</b> kann die
      Darstellung des Textes geändert und zwischen der ursprünglichen Textstruktur
      und einer vereinfachten Version (Lesefassung) ausgewählt werden. Dabei
      besteht die Möglichkeit, Abkürzungen und Schreiber ein- oder auszublenden. Über die
      Schaltfläche <b>JSON herunterladen</b> (unter <b>Arbeitsmaterial</b>) kann eine JSON-Datei heruntergeladen
      werden, die die zu "Arbeitsbereich" hinzugefügten Bücher und die auf jeder
      Tafel aktivierten Ansichten (Transkription, Struktur, Digitalisat, Schreiber, Info)
      enthält. Auf diese Weise können Arbeiten über einen längeren Zeitraum
      aufbewahrt werden und auch nach mehreren Tagen wieder aufgenommen oder mit
      einem Kollegen geteilt werden. Die JSON-Datei kann über die Schaltfläche
      <b>Ressource hinzufügen</b> hochgeladen werden; dann die Datei zum Öffnen im
      Abschnitt <b>JSON hochladen</b> auswählen.</p></span><span lang="en">
   <p>All textual witnesses of the <i>Decretum Burchardi</i> will
      be gradually included and made available in a manuscript database in the
      <a href="../html/mss.html">Manuscripts</a> section. The parts that have already been transcribed can be
      found via the button <b>Add book to Workspace</b> on each web page of the listed
      manuscripts. All accompanying texts of the decree will be listed and
      enriched with bibliographical and editorial references, which also reveal
      any dependencies between the manuscripts. The aim is to provide a
      multifunctional tool for research into the <i>Decretum
         Burchardi</i>, which goes beyond a mere listing of the manuscripts.</p>
   <p>The <a href="../html/desktop.html">Workspace</a> area provides a digital environment inspired by Burchard's desk during the
      writing of the decree. Here, using the <b>Add resource</b> button (under <b>Work material</b>), you can add
      the transcriptions of the books from the Bamberg, Frankfurt, Cologne, and
      Vatican manuscripts that you wish to view and compare. Each book is enriched
      with a transcription of the text, a view of its structure, digitized images
      of the manuscript and metadata. Using the <b>Transcription views</b>
      button, you can change the presentation of the text and choose between the
      original text structure and a simplified version (reading version). It is
      also possible to show or hide abbreviations and scribes. The <b>Download JSON</b> button (under <b>Work material</b>) can
      be used to download a JSON file containing the books added to Workspace and
      the views activated on each panel (Transcription, Structure, Digital copy, Scribe, and Info).
      In this way, work can be stored over a longer period of time and can also be
      resumed after several days or shared with a colleague. The JSON file can be
      uploaded via the <b>Add resource</b> button; then select the file to open in the
      <b>Upload JSON</b> section.</p></span></div>